# Project Context

This is a test project for experimenting with Databricks MCP tools and Claude Code.

## Available Tools

You have access to Databricks MCP tools prefixed with `mcp__databricks__`. Use `/mcp` to see the list of available tools.

## Skills

Load skills for detailed guidance:
- `skill: "agent-bricks"` - Knowledge Assistants, Genie Spaces, Multi-Agent Supervisors
- `skill: "asset-bundles"` - Databricks Asset Bundles
- `skill: "databricks-aibi-dashboards"` - Databricks AI/BI Dashboards
- `skill: "databricks-app-apx"` - Full-stack apps with APX framework
- `skill: "databricks-app-python"` - Python apps with Dash, Streamlit, Flask
- `skill: "databricks-config"` - Profile authentication setup
- `skill: "databricks-docs"` - Documentation reference
- `skill: "databricks-jobs"` - Lakeflow Jobs and workflows
- `skill: "databricks-python-sdk"` - Python SDK patterns
- `skill: "databricks-unity-catalog"` - System tables for lineage, audit, billing
- `skill: "mlflow-evaluation"` - MLflow evaluation and trace analysis
- `skill: "model-serving"` - Model Serving deployment and endpoint management
- `skill: "spark-declarative-pipelines"` - Spark Declarative Pipelines
- `skill: "synthetic-data-generation"` - Test data generation
- `skill: "unstructured-pdf-generation"` - Generate synthetic PDFs for RAG

## Testing Workflow

1. Start with simple queries to verify MCP connection works
2. Test individual tools before combining them
3. Use skills when building pipelines or complex workflows

## Notes

This is a sandbox for testing - feel free to create files, run queries, and experiment.
